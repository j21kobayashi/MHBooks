{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三目並べ：協調動作（引き分けを目指す）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境クラス\n",
    "行動を受け取り状態を遷移させ、報酬を与える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self):\n",
    "        self.Reset()\n",
    "#初期化\n",
    "    def Reset(self):\n",
    "        self.state = np.zeros(9, dtype=np.int32)#マスの設定\n",
    "        return self.state\n",
    "#行動による状態変化\n",
    "    def Step(self, action, turn):\n",
    "        rewards = [0,0]\n",
    "        done = False\n",
    "        if self.state[action] != 0:#すでに〇か×が書かれているところに打った場合\n",
    "            done = True\n",
    "            rewards[turn] = -2#打ったエージェントだけマイナスの報酬\n",
    "            return self.state, rewards, done\n",
    "        self.state[action] = turn+1\n",
    "        #3つ並んだかを判定\n",
    "        ptn = [[0,1,2],[3,4,5],[6,7,8],[0,3,6],[1,4,7],[2,5,8],[0,4,8],[2,4,6]]\n",
    "        for i in range(8):\n",
    "            if self.state[ptn[i][0]] == turn+1 and \\\n",
    "               self.state[ptn[i][1]] == turn+1 and \\\n",
    "               self.state[ptn[i][2]] == turn+1:\n",
    "                   rewards[turn] = -1#勝ったエージェントにもマイナスの報酬\n",
    "                   rewards[(turn+1)%2] = -1#負けたエージェントにマイナスの報酬\n",
    "                   done = True\n",
    "                   return self.state, rewards, done            \n",
    "        return self.state, rewards, done\n",
    "    def ShowBoard(self):\n",
    "        mb = {0:' ', 1:'O', 2:'X'}\n",
    "        i=0\n",
    "        print(mb[self.state[i*3]], \"|\", mb[self.state[i*3+1]], \"|\", mb[self.state[i*3+2]] )\n",
    "        print(\"----------\" )\n",
    "        i=1\n",
    "        print(mb[self.state[i*3]], \"|\", mb[self.state[i*3+1]], \"|\", mb[self.state[i*3+2]] )\n",
    "        print(\"----------\" )\n",
    "        i=2\n",
    "        print(mb[self.state[i*3]], \"|\", mb[self.state[i*3+1]], \"|\", mb[self.state[i*3+2]] )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エージェントクラス\n",
    "状態を観測し、行動を決定し、状態・行動・報酬からQ値を更新する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, ID, train=True):\n",
    "        self.ID = ID\n",
    "        if train:#学習時のQ値\n",
    "            print(\"Training\")\n",
    "            self.QV=np.zeros((3**9,9), dtype=np.float32)\n",
    "        else:#対戦時のQ値の読み込み\n",
    "            print(\"Game Start\")\n",
    "            fn = 'Q'+str(ID)+'value.txt'\n",
    "            self.QV = np.loadtxt(fn)\n",
    "#行動の選択\n",
    "    def GetAction(self, state, epsilon):\n",
    "        s = 0\n",
    "        for i in range(9):\n",
    "            s = s + state[i]*(3**i)\n",
    "        if epsilon > np.random.uniform(0, 1):#徐々に最適行動のみをとる、ε-greedy法\n",
    "            next_action = np.random.choice(range(9))\n",
    "        else:\n",
    "            a = np.where(self.QV[s]==self.QV[s].max())[0]\n",
    "            next_action = np.random.choice(a)\n",
    "        return next_action\n",
    "    def UpdateQValue(self, action, reward, state, state_old):\n",
    "        s = 0\n",
    "        so = 0\n",
    "        for i in range(9):\n",
    "            s = s + state[i]*(3**i)\n",
    "            so = so + state_old[i]*(3**i)\n",
    "        alpha, gamma = 0.5, 0.9\n",
    "        maxQ = np.max(self.QV[s])\n",
    "        self.QV[so,action] = (1-alpha)*self.QV[so,action]+alpha*(reward + gamma*maxQ);\n",
    "    def SaveQValue(self):\n",
    "        fn = 'Q'+str(self.ID)+'value.txt'\n",
    "        np.savetxt(fn, self.QV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のための試行の繰り返し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Training\n",
      "[847, 8811, 342] 10000\n",
      "[376, 5166, 4458] 10000\n",
      "[355, 4762, 4883] 10000\n",
      "[322, 4474, 5204] 10000\n",
      "[288, 4180, 5532] 10000\n",
      "[255, 4044, 5701] 10000\n",
      "[276, 3950, 5774] 10000\n",
      "[299, 3961, 5740] 10000\n",
      "[301, 3753, 5946] 10000\n",
      "[303, 3773, 5924] 10000\n",
      "[342, 3763, 5895] 10000\n",
      "[313, 3659, 6028] 10000\n",
      "[321, 3662, 6017] 10000\n",
      "[304, 3629, 6067] 10000\n",
      "[326, 3684, 5990] 10000\n",
      "[342, 3658, 6000] 10000\n",
      "[337, 3657, 6006] 10000\n",
      "[355, 3636, 6009] 10000\n",
      "[412, 3672, 5916] 10000\n",
      "[349, 3507, 6144] 10000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "num_episodes = 200000#100000  #総試行回数\n",
    "env = Environment()\n",
    "agent = [Agent(0), Agent(1)]\n",
    "for episode in range(num_episodes):  #試行数分繰り返す\n",
    "    if episode%10000==0:\n",
    "        wins = [0,0,0]\n",
    "    state = env.Reset()\n",
    "    state_old = [state,state]\n",
    "    actions = [0,0]\n",
    "    epsilon = (1 / (episode + 1))+0.1\n",
    "    done = False\n",
    "    for step in range(9):\n",
    "        s0 = step%2\n",
    "        s1 = (step+1)%2\n",
    "        actions[s0] = agent[s0].GetAction(state, epsilon)\n",
    "        state_old[s0] = np.copy(state)\n",
    "        state, rewards, done = env.Step(actions[s0], s0)\n",
    "        agent[s1].UpdateQValue(actions[s1], rewards[s1], state, state_old[s1])\n",
    "        if done==True:\n",
    "            agent[s0].UpdateQValue(actions[s0], rewards[s0], state, state_old[s0])\n",
    "            if rewards[s0]==-1:#1列できた場合\n",
    "                wins[0]+=1\n",
    "            if rewards[s0]==-2:#反則での勝敗数\n",
    "                wins[1]+=1\n",
    "            break\n",
    "    if done==False:\n",
    "        wins[2]+=1\n",
    "        rewards=[1,1]\n",
    "        agent[s1].UpdateQValue(actions[s1], rewards[s1], state, state_old[s1])\n",
    "        agent[s0].UpdateQValue(actions[s0], rewards[s0], state, state_old[s0])\n",
    "    if (episode+1)%10000==0:\n",
    "        print(wins,sum(wins))\n",
    "\n",
    "agent[0].SaveQValue()\n",
    "agent[1].SaveQValue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対戦のための表示設定\n",
    "最初の盤面の表示用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_InitBoard():\n",
    "    i=0\n",
    "    print(i*3, \"|\", i*3+1, \"|\", i*3+2 )\n",
    "    print(\"----------\" )\n",
    "    i=1\n",
    "    print(i*3, \"|\", i*3+1, \"|\", i*3+2 )\n",
    "    print(\"----------\" )\n",
    "    i=2\n",
    "    print(i*3, \"|\", i*3+1, \"|\", i*3+2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対戦（人間が先攻）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 1 | 2\n",
      "----------\n",
      "3 | 4 | 5\n",
      "----------\n",
      "6 | 7 | 8\n",
      "Game Start\n",
      "[0-8]0\n",
      "O |   |  \n",
      "----------\n",
      "  |   |  \n",
      "----------\n",
      "  |   |  \n",
      "Agent action: 6\n",
      "O |   |  \n",
      "----------\n",
      "  |   |  \n",
      "----------\n",
      "X |   |  \n",
      "[0-8]4\n",
      "O |   |  \n",
      "----------\n",
      "  | O |  \n",
      "----------\n",
      "X |   |  \n",
      "Agent action: 1\n",
      "O | X |  \n",
      "----------\n",
      "  | O |  \n",
      "----------\n",
      "X |   |  \n",
      "[0-8]5\n",
      "O | X |  \n",
      "----------\n",
      "  | O | O\n",
      "----------\n",
      "X |   |  \n",
      "Agent action: 3\n",
      "O | X |  \n",
      "----------\n",
      "X | O | O\n",
      "----------\n",
      "X |   |  \n",
      "[0-8]7\n",
      "O | X |  \n",
      "----------\n",
      "X | O | O\n",
      "----------\n",
      "X | O |  \n",
      "Agent action: 8\n",
      "O | X |  \n",
      "----------\n",
      "X | O | O\n",
      "----------\n",
      "X | O | X\n",
      "[0-8]2\n",
      "O | X | O\n",
      "----------\n",
      "X | O | O\n",
      "----------\n",
      "X | O | X\n",
      "Draw!\n"
     ]
    }
   ],
   "source": [
    "show_InitBoard()\n",
    "\n",
    "env = Environment()\n",
    "agent = Agent(1,False)\n",
    "state = env.Reset()\n",
    "state_old = [state,state]\n",
    "actions = [0,0]\n",
    "step = 0\n",
    "while(1):\n",
    "    actions[0] = int(input('[0-8]'))\n",
    "    state, rewards, done = env.Step(actions[0], 0)\n",
    "    env.ShowBoard()\n",
    "    if done==True:\n",
    "        if rewards[0]==-2:\n",
    "            print('Penalty. You lose.')\n",
    "        else:\n",
    "            print('You win!!!')\n",
    "        break\n",
    "    step +=1\n",
    "    if step==9:\n",
    "        print('Draw!')\n",
    "        break\n",
    "    actions[1] = agent.GetAction(state, 0)\n",
    "    print(\"Agent action:\", actions[1])\n",
    "    state, rewards, done = env.Step(actions[1], 1)\n",
    "    env.ShowBoard()\n",
    "    if done==True:\n",
    "        if rewards[1]==-2:\n",
    "            print('Penalty. You win.')\n",
    "        else:\n",
    "            print('You loose.')\n",
    "        break\n",
    "    step +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対戦（人間が後攻）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 | 1 | 2\n",
      "----------\n",
      "3 | 4 | 5\n",
      "----------\n",
      "6 | 7 | 8\n",
      "Game Start\n",
      "Agent action: 1\n",
      "  | O |  \n",
      "----------\n",
      "  |   |  \n",
      "----------\n",
      "  |   |  \n",
      "[0-8]0\n",
      "X | O |  \n",
      "----------\n",
      "  |   |  \n",
      "----------\n",
      "  |   |  \n",
      "Agent action: 8\n",
      "X | O |  \n",
      "----------\n",
      "  |   |  \n",
      "----------\n",
      "  |   | O\n",
      "[0-8]6\n",
      "X | O |  \n",
      "----------\n",
      "  |   |  \n",
      "----------\n",
      "X |   | O\n",
      "Agent action: 3\n",
      "X | O |  \n",
      "----------\n",
      "O |   |  \n",
      "----------\n",
      "X |   | O\n",
      "[0-8]2\n",
      "X | O | X\n",
      "----------\n",
      "O |   |  \n",
      "----------\n",
      "X |   | O\n",
      "Agent action: 4\n",
      "X | O | X\n",
      "----------\n",
      "O | O |  \n",
      "----------\n",
      "X |   | O\n",
      "[0-8]7\n",
      "X | O | X\n",
      "----------\n",
      "O | O |  \n",
      "----------\n",
      "X | X | O\n",
      "Agent action: 7\n",
      "X | O | X\n",
      "----------\n",
      "O | O |  \n",
      "----------\n",
      "X | X | O\n",
      "You loose.\n"
     ]
    }
   ],
   "source": [
    "show_InitBoard()\n",
    "\n",
    "env = Environment()\n",
    "agent = Agent(0,False)\n",
    "state = env.Reset()\n",
    "state_old = [state,state]\n",
    "actions = [0,0]\n",
    "step = 0\n",
    "while(1):\n",
    "    actions[0] = agent.GetAction(state, 0)\n",
    "    print(\"Agent action:\", actions[0])\n",
    "    state, rewards, done = env.Step(actions[0], 0)\n",
    "    env.ShowBoard()\n",
    "    if done==True:\n",
    "        if rewards[0]==-1:\n",
    "            print('Penalty. You win.')\n",
    "        else:\n",
    "            print('You loose.')\n",
    "        break\n",
    "    step +=1\n",
    "    if step==9:\n",
    "        print('Draw!')\n",
    "        break\n",
    "    actions[1] = int(input('[0-8]'))\n",
    "    state, rewards, done = env.Step(actions[1], 1)\n",
    "    env.ShowBoard()\n",
    "    if done==True:\n",
    "        if rewards[1]==-2:\n",
    "            print('Penalty. You lose.')\n",
    "        else:\n",
    "            print('You win!!!')\n",
    "        break\n",
    "    step +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
